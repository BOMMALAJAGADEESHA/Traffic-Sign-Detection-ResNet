{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqldLiIliSBr"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pi7BJlJ_iPSk"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyYKNL9oiWrj"
      },
      "outputs": [],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZDHUiO-iWoD"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import PIL.Image as Image\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "from torch.optim import lr_scheduler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from glob import glob\n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "from torch import nn, optim\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gwjb3TdaiWla"
      },
      "outputs": [],
      "source": [
        "!wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip\n",
        "!unzip -qq GTSRB_Final_Training_Images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSYXMeBWiWjF"
      },
      "outputs": [],
      "source": [
        "train_folders = sorted(glob('GTSRB/Final_Training/Images/*'))\n",
        "len(train_folders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocp9FyNciWb7"
      },
      "outputs": [],
      "source": [
        "def load_image(img_path, resize=True):\n",
        "  img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  if resize:\n",
        "    img = cv2.resize(img, (64, 64), interpolation = cv2.INTER_AREA)\n",
        "\n",
        "  return img\n",
        "\n",
        "def show_image(img_path):\n",
        "  img = load_image(img_path)\n",
        "  plt.imshow(img)\n",
        "  plt.axis('off')\n",
        "\n",
        "def show_sign_grid(image_paths):\n",
        "  images = [load_image(img) for img in image_paths]\n",
        "  images = torch.as_tensor(images)\n",
        "  images = images.permute(0, 3, 1, 2)\n",
        "  grid_img = torchvision.utils.make_grid(images, nrow=11)\n",
        "  plt.figure(figsize=(24, 12))\n",
        "  plt.imshow(grid_img.permute(1, 2, 0))\n",
        "  plt.axis('off');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ocds0A9jCT9"
      },
      "outputs": [],
      "source": [
        "sample_images = [np.random.choice(glob(f'{tf}/*ppm')) for tf in train_folders]\n",
        "show_sign_grid(sample_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWEp7z_ZjDW9"
      },
      "outputs": [],
      "source": [
        "img_path = glob(f'{train_folders[16]}/*ppm')[1]\n",
        "\n",
        "show_image(img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbA1KSawjDTX"
      },
      "outputs": [],
      "source": [
        "class_names = ['Speed limit (20km/h)','Speed limit (30km/h)','Speed limit (50km/h)','Speed limit (60km/h)','Speed limit (70km/h)',\n",
        "'Speed limit (80km/h)','End of speed limit (80km/h)','Speed limit (100km/h)','Speed limit (120km/h)','No passing',\n",
        "'No passing for vehicles over 3.5 metric tons','Right-of-way at the next intersection','Priority road','Yield','Stop','No vehicles',\n",
        "'Vehicles over 3.5 metric tons prohibited','No entry','General caution','Dangerous curve to the left','Dangerous curve to the right',\n",
        "'Double curve','Bumpy road','Slippery road','Road narrows on the right','Road work','Traffic signals','Pedestrians','Children crossing',\n",
        "'Bicycles crossing','Beware of ice/snow','Wild animals crossing','End of all speed and passing limits','Turn right ahead','Turn left ahead',\n",
        "'Ahead only','Go straight or right','Go straight or left','Keep right','Keep left','Roundabout mandatory','End of no passing',\n",
        "'End of no passing by vehicles over 3.5 metric tons']\n",
        "\n",
        "class_indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,28,39,40,41,42]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggu4OKCnjDQu"
      },
      "outputs": [],
      "source": [
        "!rm -rf data\n",
        "\n",
        "DATA_DIR = Path('data')\n",
        "\n",
        "DATASETS = ['train', 'val', 'test']\n",
        "\n",
        "for ds in DATASETS:\n",
        "  for cls in class_names:\n",
        "    (DATA_DIR / ds / cls).mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Xi-FQc7kQDq"
      },
      "outputs": [],
      "source": [
        "for i, cls_index in enumerate(class_indices):\n",
        "  image_paths = np.array(glob(f'{train_folders[cls_index]}/*.ppm'))\n",
        "  class_name = class_names[i]\n",
        "  print(f'{class_name}: {len(image_paths)}')\n",
        "  np.random.shuffle(image_paths)\n",
        "\n",
        "  ds_split = np.split(\n",
        "    image_paths,\n",
        "    indices_or_sections=[int(.8*len(image_paths)), int(.9*len(image_paths))]\n",
        "  )\n",
        "\n",
        "  dataset_data = zip(DATASETS, ds_split)\n",
        "\n",
        "  for ds, images in dataset_data:\n",
        "    for img_path in images:\n",
        "      shutil.copy(img_path, f'{DATA_DIR}/{ds}/{class_name}/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmT1kHqzkRlu"
      },
      "outputs": [],
      "source": [
        "mean_nums = [0.485, 0.456, 0.406]\n",
        "std_nums = [0.229, 0.224, 0.225]\n",
        "\n",
        "transforms = {'train': T.Compose([\n",
        "  T.RandomResizedCrop(size=256),\n",
        "  T.RandomRotation(degrees=15),\n",
        "  T.RandomHorizontalFlip(),\n",
        "  T.ToTensor(),\n",
        "  T.Normalize(mean_nums, std_nums)\n",
        "]), 'val': T.Compose([\n",
        "  T.Resize(size=256),\n",
        "  T.CenterCrop(size=224),\n",
        "  T.ToTensor(),\n",
        "  T.Normalize(mean_nums, std_nums)\n",
        "]), 'test': T.Compose([\n",
        "  T.Resize(size=256),\n",
        "  T.CenterCrop(size=224),\n",
        "  T.ToTensor(),\n",
        "  T.Normalize(mean_nums, std_nums)\n",
        "]),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgTOkPGfkdHo"
      },
      "outputs": [],
      "source": [
        "image_datasets = {\n",
        "  d: ImageFolder(f'{DATA_DIR}/{d}', transforms[d]) for d in DATASETS\n",
        "}\n",
        "\n",
        "data_loaders = {\n",
        "  d: DataLoader(image_datasets[d], batch_size=4, shuffle=True, num_workers=4)\n",
        "  for d in DATASETS\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s-sH6L3kkDA"
      },
      "outputs": [],
      "source": [
        "dataset_sizes = {d: len(image_datasets[d]) for d in DATASETS}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "dataset_sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImywvOMnkj_n"
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None):\n",
        "  inp = inp.numpy().transpose((1, 2, 0))\n",
        "  mean = np.array([mean_nums])\n",
        "  std = np.array([std_nums])\n",
        "  inp = std * inp + mean\n",
        "  inp = np.clip(inp, 0, 1)\n",
        "  plt.imshow(inp)\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.axis('off')\n",
        "\n",
        "inputs, classes = next(iter(data_loaders['train']))\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZ124A51kj9M"
      },
      "outputs": [],
      "source": [
        "def create_model(n_classes):\n",
        "  model = models.resnet34(pretrained=True)\n",
        "\n",
        "  n_features = model.fc.in_features\n",
        "  model.fc = nn.Linear(n_features, n_classes)\n",
        "\n",
        "  return model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U29uK15Bktp5"
      },
      "outputs": [],
      "source": [
        "base_model = create_model(len(class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNHAtdv7ktmd"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for inputs, labels in data_loader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == labels)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1wo2mDxktkQ"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in data_loader:\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, labels)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == labels)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYgcF7wbk_AM"
      },
      "outputs": [],
      "source": [
        "def train_model(model, data_loaders, dataset_sizes, device, n_epochs=10):\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "  scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "  loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "  history = defaultdict(list)\n",
        "  best_accuracy = 0\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{n_epochs}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    train_acc, train_loss = train_epoch(\n",
        "      model,\n",
        "      data_loaders['train'],\n",
        "      loss_fn,\n",
        "      optimizer,\n",
        "      device,\n",
        "      scheduler,\n",
        "      dataset_sizes['train']\n",
        "    )\n",
        "\n",
        "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "    val_acc, val_loss = eval_model(\n",
        "      model,\n",
        "      data_loaders['val'],\n",
        "      loss_fn,\n",
        "      device,\n",
        "      dataset_sizes['val']\n",
        "    )\n",
        "\n",
        "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "    print()\n",
        "\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "\n",
        "    if val_acc > best_accuracy:\n",
        "      torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "      best_accuracy = val_acc\n",
        "\n",
        "  print(f'Best val accuracy: {best_accuracy}')\n",
        "\n",
        "  model.load_state_dict(torch.load('best_model_state.bin'))\n",
        "\n",
        "  return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN3xxvAbk-8q",
        "outputId": "3caaec7c-a6ab-4134-eeef-5f3b62047189"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "----------\n",
            "Train loss 0.9211992688434233 accuracy 0.7373519556779352\n",
            "Val   loss 0.1474636065653425 accuracy 0.9463906581740976\n",
            "\n",
            "Epoch 2/10\n",
            "----------\n",
            "Train loss 0.4620074618724484 accuracy 0.8561855157084564\n",
            "Val   loss 0.08843709910479251 accuracy 0.9601910828025477\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n",
            "Train loss 0.39443874875979223 accuracy 0.8724745380353648\n",
            "Val   loss 0.11262180319219589 accuracy 0.9554140127388535\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n",
            "Train loss 0.37034033184036275 accuracy 0.8811000895730352\n",
            "Val   loss 0.09697103372207609 accuracy 0.953556263269639\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n",
            "Train loss 0.3375842592640664 accuracy 0.8890289619480476\n",
            "Val   loss 0.05809488942884677 accuracy 0.9697452229299363\n",
            "\n",
            "Epoch 6/10\n",
            "----------\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "base_model, history = train_model(base_model, data_loaders, dataset_sizes, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LM2NnXAjk-6a"
      },
      "outputs": [],
      "source": [
        "def plot_training_history(history):\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "  ax1.plot(history['train_loss'], label='train loss')\n",
        "  ax1.plot(history['val_loss'], label='validation loss')\n",
        "\n",
        "  ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "  ax1.set_ylim([-0.05, 1.05])\n",
        "  ax1.legend()\n",
        "  ax1.set_ylabel('Loss')\n",
        "  ax1.set_xlabel('Epoch')\n",
        "\n",
        "  ax2.plot(history['train_acc'], label='train accuracy')\n",
        "  ax2.plot(history['val_acc'], label='validation accuracy')\n",
        "\n",
        "  ax2.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "  ax2.set_ylim([-0.05, 1.05])\n",
        "  ax2.legend()\n",
        "\n",
        "  ax2.set_ylabel('Accuracy')\n",
        "  ax2.set_xlabel('Epoch')\n",
        "\n",
        "  fig.suptitle('Training history')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "inBIY7RPlTBq"
      },
      "outputs": [],
      "source": [
        "def plot_training_history(history):\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "  ax1.plot(history['train_loss'], label='train loss')\n",
        "  ax1.plot(history['val_loss'], label='validation loss')\n",
        "\n",
        "  ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "  ax1.set_ylim([-0.05, 1.05])\n",
        "  ax1.legend()\n",
        "  ax1.set_ylabel('Loss')\n",
        "  ax1.set_xlabel('Epoch')\n",
        "\n",
        "  #ax2.plot(history['train_acc'], label='train accuracy')\n",
        "  #ax2.plot(history['val_acc'], label='validation accuracy')\n",
        "  ax2.plot([t.cpu().numpy() for t in history['train_acc']], label='train accuracy')\n",
        "  ax2.plot([t.cpu().numpy() for t in history['val_acc']], label='validation accuracy')\n",
        "\n",
        "  ax2.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "  ax2.set_ylim([-0.05, 1.05])\n",
        "  ax2.legend()\n",
        "\n",
        "  ax2.set_ylabel('Accuracy')\n",
        "  ax2.set_xlabel('Epoch')\n",
        "\n",
        "  fig.suptitle('Training history')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8yJujWttlXKt"
      },
      "outputs": [],
      "source": [
        "plot_training_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "n7t-TCx5lYWs"
      },
      "outputs": [],
      "source": [
        "def show_predictions(model, class_names, n_images=6):\n",
        "  model = model.eval()\n",
        "  images_handeled = 0\n",
        "  plt.figure()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, (inputs, labels) in enumerate(data_loaders['test']):\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "\n",
        "      for j in range(inputs.shape[0]):\n",
        "        images_handeled += 1\n",
        "        ax = plt.subplot(2, n_images//2, images_handeled)\n",
        "        ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
        "        imshow(inputs.cpu().data[j])\n",
        "        ax.axis('off')\n",
        "\n",
        "        if images_handeled == n_images:\n",
        "          return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YqLJnzzFlYMt"
      },
      "outputs": [],
      "source": [
        "show_predictions(base_model,  class_names,  n_images=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ETaH5oD9lfVk"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  predictions = []\n",
        "  real_values = []\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in data_loader:\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "      predictions.extend(preds)\n",
        "      real_values.extend(labels)\n",
        "  predictions = torch.as_tensor(predictions).cpu()\n",
        "  real_values = torch.as_tensor(real_values).cpu()\n",
        "  return predictions, real_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B2tnuNREluxY"
      },
      "outputs": [],
      "source": [
        "y_pred, y_test = get_predictions(base_model, data_loaders['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L4bCl7J7lut4"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5oS5rrKWl1O9"
      },
      "outputs": [],
      "source": [
        "def show_confusion_matrix(confusion_matrix, class_names):\n",
        "\n",
        "  cm = confusion_matrix.copy()\n",
        "\n",
        "  cell_counts = cm.flatten()\n",
        "\n",
        "  cm_row_norm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "  row_percentages = [\"{0:.2f}\".format(value) for value in cm_row_norm.flatten()]\n",
        "\n",
        "  cell_labels = [f\"{cnt}\\n{per}\" for cnt, per in zip(cell_counts, row_percentages)]\n",
        "  cell_labels = np.asarray(cell_labels).reshape(cm.shape[0], cm.shape[1])\n",
        "\n",
        "  df_cm = pd.DataFrame(cm_row_norm, index=class_names, columns=class_names)\n",
        "\n",
        "  hmap = sns.heatmap(df_cm, annot=cell_labels, fmt=\"\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=1, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('True Sign')\n",
        "  plt.xlabel('Predicted Sign');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p1hzH6WVl1EK"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "show_confusion_matrix(cm, class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u2CVJc1_Z_8"
      },
      "source": [
        "GUI FOR TRAFFIC SIGN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KL7yufTjl88o"
      },
      "outputs": [],
      "source": [
        "pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iuoRVIvGl8xA"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYzQ1KIvmEh4"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define function to predict output\n",
        "def predict(image):\n",
        "    image = Image.fromarray(image)  # Convert numpy array to PIL image\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(size=256),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean_nums, std_nums)\n",
        "    ])\n",
        "    input_tensor = preprocess(image).unsqueeze(0)\n",
        "    input_tensor = input_tensor.to(device)\n",
        "    base_model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = base_model(input_tensor)\n",
        "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "    predicted_index = torch.argmax(probabilities).item()\n",
        "    predicted_class = class_names[predicted_index]\n",
        "    return predicted_class\n",
        "\n",
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=\"image\",\n",
        "    outputs=\"text\",\n",
        "    title=\"Traffic Sign Detection\",\n",
        "    description=\"Upload an image and get the predicted class label.\"\n",
        ")\n",
        "iface.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}